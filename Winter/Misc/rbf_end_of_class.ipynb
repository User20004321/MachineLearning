{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd3bbf5",
   "metadata": {},
   "source": [
    "# Radial Basis Networks\n",
    "\n",
    "What are our learning objectives for this lesson?\n",
    "\n",
    "* Learn how to set up a Radial Basis Network\n",
    "* Understand how hyperparameters changes learning\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Marsland, Stephen. Machine Learning: An Algorithmic Perspective 2nd ed. (2015).\n",
    "\n",
    "## Lab Tasks\n",
    "\n",
    "1. Set up a radial basis network to solve the XOR problem\n",
    "   * declare basic parameters of the network\n",
    "   * initialize weight vector\n",
    "   * write a function that computes the outputs of the radial basis layer\n",
    "2. Train and test the network \n",
    "   * write a train function\n",
    "   * run a test to make sure your network is capable of solving XOR\n",
    "   * play around with the hyperparameters (learning rate $\\eta$, $\\sigma$ in the radial basis function, etc)\n",
    "3. Create a k-means algorithm to initialize the positions of the RBF centers\n",
    "\n",
    "### Set up a radial basis network\n",
    "\n",
    "In this section we will set up a radial basis network with an input layer, a layer of radial basis nodes ,and an output layer. The structure if this network has the same amount of input and output nodes with the Perceptron model from last week, but we will implement an additional hidden layer inbetween the input and output layer. \n",
    "\n",
    "The exact network we will be implementing for the XOR problem is depicted below.\n",
    "\n",
    "![radial-basis-for-XOR](https://raw.githubusercontent.com/FifthEpoch/Hosted_Images/main/XOR-RADIAL-BASIS-NET.png)\n",
    "\n",
    "\n",
    "#### How to pick the centers of the receptive fields for the XOR problem\n",
    "\n",
    "We will start with a simple strategy in positioning the RBF nodes, and work our way to using strategy that requires more steps like k-mean clustering later in this lab. \n",
    "\n",
    "For solving the XOR problem, we can represent the RBFs as the four possible cases: \n",
    "\n",
    "$$(0, 0), (0, 1), (1, 0), (1, 1)$$\n",
    "\n",
    "so that the nodes are representative of typical inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8869f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "XOR_targets = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# TODO: fill in what the center of each RBF nodes would be.\n",
    "#       they should reflect all 4 cases of our inputs.\n",
    "RBF_nodes_centers = inputs    #input data is centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400a379",
   "metadata": {},
   "source": [
    "#### Setting up the weights vector\n",
    "\n",
    "Recall that we have initialized a weight vector for a Perceptron model last week. The weight vector has a length of $n+1$ with $n$ representing the number of inputs. We are repeating the same process for the radial basis network for today's lab. Initialize weight vector $\\vec{w}$ such that:\n",
    "\n",
    "$$ \\vec{w} = [w_0, w_1, ..., w_n] $$\n",
    "\n",
    "with $w_0$ being the weight associated with the bias node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6779549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized weights: \n",
      "[[-0.03934513]\n",
      " [-0.00886318]\n",
      " [ 0.01240771]\n",
      " [-0.04726754]]\n"
     ]
    }
   ],
   "source": [
    "# PARAM\n",
    "n_in = np.shape(inputs)[1]   # refers to # of columns/features\n",
    "\n",
    "# TODO: how many nodes is in the RBF layer, fill in the variable\n",
    "n_rbf = 4\n",
    "\n",
    "\n",
    "n_out = 1\n",
    "eta = 0.2\n",
    "\n",
    "# TODO: initialize the weight vector\n",
    "# hint: weights.shape[1] should equals to 1\n",
    "weights = np.random.rand(4,1) * 0.1 -0.05\n",
    "\n",
    "\n",
    "print(f'initialized weights: \\n{weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dca2e7",
   "metadata": {},
   "source": [
    "#### Radial Basis\n",
    "\n",
    "Here we will be using the notations introduced in the illustration of the network above. The radial basis function is represented by $h$ in the illustration, we make distinction between $h_0$, $h_1$, and so on because the center $\\vec{c}$ of the RBF nodes are different, thus giving a slighly different equation. \n",
    "\n",
    "Below we will quickly review all the neccessary formulas we need in computing the output of the radial basis layer. The general equation of radial basis is:\n",
    "\n",
    "$$ h(\\vec{x}) = \\text{exp}(\\frac{-|\\vec{x} - \\vec{c}|^2}{2\\sigma^2}) = y$$\n",
    "\n",
    "where __$\\sigma$ is set to $0.1$ arbitrarily__ (for now). Furthermore, $\\vec{x} = [x_0 \\text{ } x_1]^T$, $\\vec{c} = [c_0 \\text{ } c_1]^T$ denotes the coordinates of the center for a given RBF, $d$ is the distance given by $|\\vec{x} - \\vec{c}|$ and $M$ is the number of RBF in the network.\n",
    "\n",
    "The distance between 2 vectors $\\vec{x}$ and $\\vec{c}$ $(\\vec{x}, \\vec{c} \\in \\mathbb{R}^n$) is given by:\n",
    "\n",
    "$$ d(\\vec{x}, \\vec{c}) = |\\vec{x} - \\vec{c}| = \\sqrt{(x_1-c_1)^2 + (x_2 - c_2)^2 + ... + (x_n - c_n)^2}$$ \n",
    "\n",
    "#### Computing the Output for the Radial Basis Layer\n",
    "\n",
    "Each RBF node takes $x_0$ and $x_1$ and computes the distance between the vector $[x_0 \\text{ } x_1]^T$ to the center of itself $[c_0 \\text{ } c_1]^T$. \n",
    "\n",
    "We loop through all the RBF nodes and process each case in the input (e.g. $x_0 = 0$ and $x_1 = 1$). The output of our RBF layer should be a matrix with each row representing the RBF node the output is associated with, and each column representing radial basis output $y$ for a particular set of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4421ec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99501248, 0.99501248, 0.99004983],\n",
       "       [0.99501248, 1.        , 0.99004983, 0.99501248],\n",
       "       [0.99501248, 0.99004983, 1.        , 0.99501248],\n",
       "       [0.99004983, 0.99501248, 0.99501248, 1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: implement a radial basis function that processes the entire input\n",
    "def get_radial_basis_outputs(_inputs, _centers, _sigma=0.1):\n",
    "    # complete this function\n",
    "    outputs = np.zeros((n_rbf, len(_inputs)))\n",
    "    _sigma2 = _sigma ** 2\n",
    "    \n",
    "    for i in range (n_rbf):\n",
    "        for j in range(len(_inputs)):\n",
    "                          outputs[i,j] = np.exp(-(np.linalg.norm(_centers[i] - inputs[j])) **2 / 2 * (_sigma2))\n",
    "                       \n",
    "    #np.exp(-np.linalg.norm(_input - _centers)/2*_sigma**2)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return outputs\n",
    "get_radial_basis_outputs(inputs, RBF_nodes_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73740f85",
   "metadata": {},
   "source": [
    "#### Other Functions We Need for this Network\n",
    "\n",
    "After we are finished with the ```get_radial_basis_outputs()``` function, we will need to implement the same 3 functions we implemented for the Perceptron model during last week's lab. \n",
    "\n",
    "Since we have already went over how these functions work, their complete implementation is going to be included below. If you didn't get to finish them from last week's lab, you are encouraged to examine them before moving on.\n",
    "\n",
    "If you the function you have implemented thus far have different dimensionality requirements for the parameters from the functions implemented below, please feel free to alter/rewrite the 3 functions below to fit your work.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321278c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_activations(_inputs, _weights, _threshold=0.0):\n",
    "    activations = np.dot(np.transpose(_inputs), _weights)\n",
    "    return np.where(activations > _threshold, 1, 0)\n",
    "\n",
    "def insert_bias(_inputs):\n",
    "    return np.insert(_inputs, 0, 1.0, axis=0)\n",
    "\n",
    "def update_weights(_inputs, _targets, _activations, _weights):\n",
    "    _weights -= eta * np.dot(_inputs, _activations - _targets)\n",
    "    return _weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535ccaa",
   "metadata": {},
   "source": [
    "### Train and Test the Network\n",
    "\n",
    "Lastly, we implement a train function to facililate training. This function should take information like our inputs, their targets, the initialized weights, and number of iterations for the training session. The output would be an updated weight vector. This updated weight vector contains all of the learning our network has done, we can consider it a form of \"memory\" for the network. Since we would like to test the network's learning, be sure to save the updated weight vector during training.\n",
    "\n",
    "Let's review the flow of data in our radial basis network briefly:\n",
    "1. radial basis layer takes $\\vec{x}$ and output $\\vec{y}$\n",
    "2. $\\vec{y}$ is sent to the output node\n",
    "3. we insert the input associated to the bias node to $\\vec{y}$\n",
    "3. sum of square and activation takes place, leaving us with a final scalar output $z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6e0254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration: 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_activations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18048\\2878185206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_radial_basis_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXOR_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18048\\2878185206.py\u001b[0m in \u001b[0;36mtrain_radial_basis_network\u001b[1;34m(_inputs, _targets, _weights, _iterations, _sigma)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mcalculate_activations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0minsert_bias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_activations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_activations' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: using all of the functions we have above, complete the training loop\n",
    "def train_radial_basis_network(_inputs, _targets, _weights, _iterations=5, _sigma=0.1):\n",
    "    for i in range(_iterations):\n",
    "        print(f'\\niteration: {i + 1}')\n",
    "        \n",
    "        calculate_activations(_inputs, _weights, _threshold=0.0)\n",
    "        insert_bias(_inputs)\n",
    "        update_weights(_inputs, _targets, _activations, _weights)\n",
    "        \n",
    "    return _weights\n",
    "\n",
    "weights = train_radial_basis_network(inputs, XOR_targets, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9441a952",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'activations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18048\\1156289318.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'accuracy: {(accuracy / len(test_target))*100.0}%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtest_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18048\\1156289318.py\u001b[0m in \u001b[0;36mtest_network\u001b[1;34m(_test_inputs, _test_targets, _weights, _sigma)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'accuracy: {(accuracy / len(test_target))*100.0}%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'activations' is not defined"
     ]
    }
   ],
   "source": [
    "test = np.array([[1,0],[1,1],[0,1],[0,0]])\n",
    "test_target = np.array([[1],[0],[1],[0]])\n",
    "\n",
    "# TODO: implement a test to check if the network solves XOR correctly.\n",
    "def test_network(_test_inputs, _test_targets, _weights, _sigma=0.1):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # check the accuracy of your trained model\n",
    "    accuracy = 0.0\n",
    "    for i in range(len(test_target)):\n",
    "        if test_target[i] == activations[i]: accuracy += 1 \n",
    "    print(f'accuracy: {(accuracy / len(test_target))*100.0}%')\n",
    "\n",
    "test_network(test, test_target, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855cacb",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "\n",
    "Now that we have a working network, we can try altering the parameters to see how they change the network's learning. \n",
    "\n",
    "For Radial Basis, each RBF node is responsible in learning within their receptive fields. What happens if all training data falls outside of their receptive fields? To illustrate the effect, we will use a set of new centers for our RBF nodes shown below. Instead of having the centers represent the typical inputs of our network, we use this set of slignly offset centers.\n",
    "\n",
    "If the training didn't work with the number of iterations, learning rate $\\eta$, and sigma $\\sigma$ value we have, try adjusting them one by one and see if learning improves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9152913c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-331f83c5bbc1>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-331f83c5bbc1>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    weights = ???\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "RBF_nodes_centers = np.array([[0.2, 0.2], [0.2, 0.8], [0.2, 0.8], [0.8, 0.8]])\n",
    "\n",
    "\n",
    "# TODO: re-initialize the weight vector here\n",
    "weights = ???\n",
    "\n",
    "\n",
    "# Train with the new radial basis layer:\n",
    "# if the current parameters are not working well for this problem\n",
    "# try changing _iterations, _sigma, and eta values below \n",
    "\n",
    "eta = 0.2\n",
    "weights = train_radial_basis_network(inputs, XOR_targets, weights, _iterations=5, _sigma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ed26e",
   "metadata": {},
   "source": [
    "__ðŸ¤” Why does nudging some parameters improve learning while nudging others don't?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb0ba6",
   "metadata": {},
   "source": [
    "## Bonus Task\n",
    "\n",
    "In most machine learning problems, there aren't clearcut \"typical\" inputs around which we define our receptive fields. In those cases, it is common to use k-mean cluster to identify centroids that work for the ranges of a dataset.\n",
    "\n",
    "### $k$-means algorithm\n",
    "\n",
    "1. Set the number $k$ to specify the number of cluster to assign\n",
    "2. Randomly initialize $k$ centroids\n",
    "3. Repeat:\n",
    "    * assign each data point to its closest centroid\n",
    "    * compute the new centroid of each cluster\n",
    "    * repeat until the centroid positions do not change\n",
    "    \n",
    "Given a set $P$ containing $n$ 2D-points $p_0$, $p_1$, ..., $p_{n-1}$, where the coordinate of $p_i$ is ($x_i$, $y_i$), the coordinate of centeroid of $X$ denoted by $c$ is:\n",
    "\n",
    "$$ c(P) = (\\frac{x_0 + x_1 + ... + x_{n-1}}{n}, \\frac{y_0 + y_1 + ... + y_{n-1}}{n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def33803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying a k\n",
    "k = 4\n",
    "# a set of 2D points that are set in the area bounded by (0, 0) and (1, 1)\n",
    "data = np.random.rand(20, 2)\n",
    "# randomly initializing k centroids\n",
    "centroids = np.random.rand(k)\n",
    "\n",
    "# TODO: implement k-mean clustering\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

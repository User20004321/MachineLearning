{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e8912a",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f7de3",
   "metadata": {},
   "source": [
    "What are our learning objectives for this lesson?\n",
    "\n",
    "* Learn how to apply Decision Trees in a classification problem\n",
    "* Get more familiar with the scikit-learn library\n",
    "\n",
    "In this lab, we will once again construct a machine learning model that predicts the species of iris based on its petal and sepal dimensions. This time, we will use another approach in the supervised learning toolboxâ€“the decision tree, instead of using the support vector machine which was used in the last lab. \n",
    "\n",
    "Beginning with the root node, every node that is not a leaf node acts as a decision node in the tree. In its essence, a decision tree architecture is where we do a greedy search to find the optimal split point in a tree. The decision nodes are where the data is split, and the leave nodes represents outputs like a class label. \n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* GÃ©ron, A. (2019). Hands-on machine learning with Scikit-Learn, Keras and TensorFlow: concepts, tools, and techniques to build intelligent systems (2nd ed.). Oâ€™Reilly.\n",
    "\n",
    "## Lab Tasks \n",
    "\n",
    "1. Import the iris dataset\n",
    "2. Read the documentation for Scikit-Learn's DecisionTreeClassifier and use it\n",
    "3. Visualize the tree using Scikit-Learn\n",
    "\n",
    "### Import the Iris Dataset\n",
    "\n",
    "* Import the Iris dataset\n",
    "* Split the dataset into train and test sets, use a 70:30 split ratio\n",
    "    * You can reduce the dimension of the data by dropping features or by projecting the inputs to a lower dimension, you can also keep the data as it is.\n",
    "\n",
    "Here are some import statements to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57016f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\davis\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\davis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\davis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\davis\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\davis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45d847fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import sklearn.tree as tree\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "356e4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import the iris datset here\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# TODO: Split the data into train and test set. \n",
    "#       Reduce the dimension if you wish, \n",
    "#       \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ebd182",
   "metadata": {},
   "source": [
    "### Select a Model\n",
    "\n",
    "Visit the [documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree) of ```sklearn.tree```, select a tree model that best fit the task we are training the model to perform. \n",
    "\n",
    "Once you have selected a model, we want to determine the depth of the tree. In Scikit-Learn, we can adjust the ```max_depth``` parameter to limit the depth the tree is allowed to grow. The deeper the tree, the more splits we make in the data, and the more complex the model will become. If the number of splits is too low, the model underfits the data and if it is too high the model overfits. \n",
    "\n",
    "Recall that the root node is considered to have a depth of 0. You can try different depths. For now, we can simply put in ```None``` (which is the default value for this optional parameter) for the parameter and see how many levels ends up in our tree.\n",
    "\n",
    "What we want to do in the cell below:\n",
    "* Set up the model of choice\n",
    "* fit the train set to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71581f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of tree: 6\n",
      "Cross-validation scores: [1.         0.93333333 1.         0.93333333 0.93333333 0.86666667\n",
      " 0.93333333 0.93333333 1.         1.        ]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set up the model of choice and fit the training data to it\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(\"Depth of tree:\", clf.get_depth())\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a26df",
   "metadata": {},
   "source": [
    "### Test the Fitted Model\n",
    "\n",
    "Visit the documentation of your particular Scikit-Learn tree model to find different built-in methods for testing your model. Try the different methods available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c667c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of tree: 6\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: Try different built-in testing methods\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Depth of tree:\", clf.get_depth())\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a519d5",
   "metadata": {},
   "source": [
    "##### ðŸ’¯ What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807143e1",
   "metadata": {},
   "source": [
    "### Visualize the Tree\n",
    "\n",
    "The decision tree model makes the internal decisions made by the model intuitive to interpret. One way to exmaple the internal decision process of a decision tree model is to print out the tree and see for ourselves what kind of decision is being made in each node. We will use a module in ```sklearn.tree``` called ```export_graphviz``` to visualize the tree.\n",
    "\n",
    "In order to visualize the graph inside of this notebook (instead of save .dot and image files in our local directory outside of the notebook), we will install and import some modules. \n",
    "\n",
    "If you wish to save the .dot graph to a local directory and convert the .dot to an image file instead, note the following:\n",
    "* pick the directory you would like to save the .dot to\n",
    "    *  ```f = open(\"some/directory/on/your/machine/iris_tree.dot\", 'w')```\n",
    "* add  ```out_file=f``` to the parameters when you call the ```export_graphviz``` function\n",
    "* you don't have to save the output of ```export_graphviz``` to a variable since the output is being saved to the specified directory\n",
    "* run ```!dot -Tpng iris_tree.dot > iris_tree.png``` in the directory where the .dot is saved to obtain a png of the tree graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c788015b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydotplus in c:\\users\\davis\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\davis\\anaconda3\\lib\\site-packages (from pydotplus) (3.0.9)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.0/47.0 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.1\n"
     ]
    }
   ],
   "source": [
    "# DELETE THIS CELL if you wish to save the image file locally\n",
    "\n",
    "!pip install pydotplus\n",
    "!pip install graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf1486",
   "metadata": {},
   "source": [
    "What we want to do here:\n",
    "* Visit the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html) of ```export_graphviz``` to find out what parameters it takes\n",
    "* Experiment with the ```max_depth```, print out the graphs with different depths, find the ```max_depth``` value that yields the highest performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c0d48c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27528\\1274166377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# TODO: fill in the parameters for this function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m dot_data = export_graphviz(\n\u001b[0m\u001b[0;32m      7\u001b[0m                             \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                             \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[1;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision, fontname)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \"\"\"\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m     \u001b[0mown_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[0mreturn_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1390\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "\n",
    "# TODO: fill in the parameters for this function\n",
    "dot_data = export_graphviz(\n",
    "                            clf, out_file=None, \n",
    "                            feature_names=iris.feature_names,  \n",
    "                            class_names=iris.target_names,  \n",
    "                            filled=True, rounded=True,  \n",
    "                            special_characters=True\n",
    " )\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "# DELETE THESE 2 LINES if you wish to save the image file locally\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3927d",
   "metadata": {},
   "source": [
    "##### What is the depth that seemed to work the best for your model? Is it deeper or shallower than the initial depth with the default setting? Do you have a hypothesis on why that might be?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
